{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gq9SA4uUc4OP"
      },
      "outputs": [],
      "source": [
        "#Team Planet hunte AI model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Exoplanet Detection Pipeline (Google Colab Ready)\n",
        "# ================================\n",
        "\n",
        "# Install pinned packages for stability\n",
        "!pip install --quiet xgboost==2.0.3 shap joblib optuna scikit-learn==1.5.2 tensorflow matplotlib seaborn\n",
        "\n",
        "# -------------------------\n",
        "# Imports & Setup\n",
        "# -------------------------\n",
        "import os, shutil, time, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "\n",
        "# ML\n",
        "import xgboost as xgb\n",
        "from xgboost.callback import EarlyStopping\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.model_selection import train_test_split, learning_curve\n",
        "from sklearn.metrics import (accuracy_score, f1_score, classification_report, confusion_matrix,\n",
        "                             roc_auc_score, roc_curve, precision_recall_curve, average_precision_score)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.base import clone\n",
        "\n",
        "# Deep learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "\n",
        "# Explainability + tuning\n",
        "import shap\n",
        "import optuna\n",
        "\n",
        "# Colab files\n",
        "from google.colab import files\n",
        "\n",
        "# -------------------------\n",
        "# Config\n",
        "# -------------------------\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "SAVE_DIR = Path(\"results_colab\")\n",
        "SAVE_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "USE_OPTUNA = False   # Set True for tuning (slower)\n",
        "N_TRIALS = 12        # Optuna trials when enabled\n",
        "FIG_DPI = 200\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
        "sns.set_palette(\"deep\")\n",
        "plt.rcParams.update({\"figure.dpi\": FIG_DPI, \"savefig.dpi\": FIG_DPI, \"font.size\": 10})\n",
        "\n",
        "def savefig(fig, name):\n",
        "    p = SAVE_DIR / f\"{name}.png\"\n",
        "    fig.savefig(p, bbox_inches=\"tight\", dpi=FIG_DPI)\n",
        "    print(\"Saved:\", p)\n",
        "\n",
        "# -------------------------\n",
        "# 1. Upload dataset\n",
        "# -------------------------\n",
        "print(\"ðŸ“‚ Upload your exoplanet_xgb_ready.csv file now\")\n",
        "uploaded = files.upload()\n",
        "dataset_name = list(uploaded.keys())[0]\n",
        "data = pd.read_csv(dataset_name).dropna(subset=[\"target\"]).reset_index(drop=True)\n",
        "\n",
        "X = data.drop(\"target\", axis=1)\n",
        "y = data[\"target\"]\n",
        "feature_names = X.columns.tolist()\n",
        "print(\"Dataset:\", data.shape, \"| Classes:\", sorted(y.unique()))\n",
        "\n",
        "# -------------------------\n",
        "# 2. Split & preprocess\n",
        "# -------------------------\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=SEED)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=SEED)\n",
        "\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_s, X_val_s, X_test_s = scaler.transform(X_train), scaler.transform(X_val), scaler.transform(X_test)\n",
        "\n",
        "print(\"Train/Val/Test:\", X_train.shape[0], X_val.shape[0], X_test.shape[0])\n",
        "\n",
        "# -------------------------\n",
        "# 3. Exploratory Plots\n",
        "# -------------------------\n",
        "fig = plt.figure(figsize=(6,4))\n",
        "sns.countplot(x=y)\n",
        "plt.title(\"ðŸ”­ Class Distribution of Exoplanets\")\n",
        "plt.xlabel(\"Target class (0=Non-planet, 1=Confirmed Exoplanet)\")\n",
        "plt.ylabel(\"Count\")\n",
        "savefig(fig, \"eda_class_counts\"); plt.close(fig)\n",
        "\n",
        "# PCA projection\n",
        "pca = PCA(n_components=2, random_state=SEED)\n",
        "X_pca2 = pca.fit_transform(X_train_s)\n",
        "fig, ax = plt.subplots(figsize=(7,5))\n",
        "sns.scatterplot(x=X_pca2[:,0], y=X_pca2[:,1], hue=y_train, s=15, alpha=0.7, palette=\"coolwarm\")\n",
        "plt.title(\"PCA Projection (2D)\")\n",
        "plt.xlabel(\"Principal Component 1 (Orbital Signature)\")\n",
        "plt.ylabel(\"Principal Component 2 (Stellar Flux)\")\n",
        "savefig(fig, \"eda_pca2\"); plt.close(fig)\n",
        "\n",
        "# Correlation heatmap\n",
        "fig, ax = plt.subplots(figsize=(10,7))\n",
        "sns.heatmap(X.corr(), cmap=\"mako\", center=0, cbar_kws={\"label\":\"Correlation\"})\n",
        "plt.title(\"Correlation Matrix of Astronomical Features\")\n",
        "savefig(fig, \"eda_corr\"); plt.close(fig)\n",
        "\n",
        "# -------------------------\n",
        "# 4. Baseline Models\n",
        "# -------------------------\n",
        "rf = RandomForestClassifier(n_estimators=300, random_state=SEED, n_jobs=-1)\n",
        "rf.fit(X_train_s, y_train)\n",
        "\n",
        "xgb_baseline = xgb.XGBClassifier(\n",
        "    objective=\"multi:softprob\", num_class=len(np.unique(y)),\n",
        "    eval_metric=\"mlogloss\", max_depth=6, learning_rate=0.1,\n",
        "    n_estimators=400, random_state=SEED, use_label_encoder=False\n",
        ")\n",
        "xgb_baseline.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False,\n",
        "                 callbacks=[EarlyStopping(rounds=30, save_best=True)])\n",
        "\n",
        "# -------------------------\n",
        "# 5. Evaluation helper\n",
        "# -------------------------\n",
        "def eval_and_save(name, model, X_e, y_true, scaled=False):\n",
        "    X_in = scaler.transform(X_e) if scaled else X_e\n",
        "    preds = model.predict(X_in)\n",
        "    acc = accuracy_score(y_true, preds)\n",
        "    f1 = f1_score(y_true, preds, average=\"weighted\")\n",
        "    print(f\"\\n{name}: Acc={acc:.4f} F1={f1:.4f}\")\n",
        "    print(classification_report(y_true, preds))\n",
        "    cm = confusion_matrix(y_true, preds)\n",
        "    fig, ax = plt.subplots(figsize=(6,5))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"rocket_r\",\n",
        "                xticklabels=sorted(y.unique()), yticklabels=sorted(y.unique()))\n",
        "    plt.title(f\"{name} Confusion Matrix\")\n",
        "    savefig(fig, f\"{name}_confusion\"); plt.close(fig)\n",
        "    return preds, acc, f1\n",
        "\n",
        "rf_preds, rf_acc, rf_f1 = eval_and_save(\"RandomForest\", rf, X_test, y_test, scaled=True)\n",
        "xgb_preds, xgb_acc, xgb_f1 = eval_and_save(\"XGBoost_baseline\", xgb_baseline, X_test, y_test, scaled=False)\n",
        "\n",
        "# -------------------------\n",
        "# 6. ROC & PR Curves\n",
        "# -------------------------\n",
        "def plot_roc_pr(model, X, y_true, name, scaled=False):\n",
        "    X_in = scaler.transform(X) if scaled else X\n",
        "    y_proba = model.predict_proba(X_in)\n",
        "    n_classes = y_proba.shape[1]\n",
        "\n",
        "    # ROC\n",
        "    fig, ax = plt.subplots(figsize=(6,5))\n",
        "    for i in range(n_classes):\n",
        "        fpr, tpr, _ = roc_curve(y_true==i, y_proba[:,i])\n",
        "        ax.plot(fpr, tpr, label=f\"Class {i}\")\n",
        "    ax.plot([0,1],[0,1],\"--\",c=\"gray\")\n",
        "    ax.set_title(f\"{name} ROC Curve\")\n",
        "    ax.set_xlabel(\"False Positive Rate\")\n",
        "    ax.set_ylabel(\"True Positive Rate\")\n",
        "    ax.legend()\n",
        "    savefig(fig, f\"{name}_roc\"); plt.close(fig)\n",
        "\n",
        "    # PR curve\n",
        "    fig, ax = plt.subplots(figsize=(6,5))\n",
        "    for i in range(n_classes):\n",
        "        prec, rec, _ = precision_recall_curve(y_true==i, y_proba[:,i])\n",
        "        ax.plot(rec, prec, label=f\"Class {i}\")\n",
        "    ax.set_title(f\"{name} Precision-Recall Curve\")\n",
        "    ax.set_xlabel(\"Recall\")\n",
        "    ax.set_ylabel(\"Precision\")\n",
        "    ax.legend()\n",
        "    savefig(fig, f\"{name}_pr\"); plt.close(fig)\n",
        "\n",
        "plot_roc_pr(rf, X_test, y_test, \"RandomForest\", scaled=True)\n",
        "plot_roc_pr(xgb_baseline, X_test, y_test, \"XGBoost\", scaled=False)\n",
        "\n",
        "# -------------------------\n",
        "# 7. Learning Curves (fixed for XGB)\n",
        "# -------------------------\n",
        "def plot_learning_curve_custom(model, X, y, name, scaled=False):\n",
        "    \"\"\"Works for sklearn-compatible models like RandomForest\"\"\"\n",
        "    from sklearn.model_selection import learning_curve\n",
        "    X_in = scaler.transform(X) if scaled else X\n",
        "    train_sizes, train_scores, val_scores = learning_curve(clone(model), X_in, y,\n",
        "                                                           cv=3, scoring=\"accuracy\",\n",
        "                                                           n_jobs=-1,\n",
        "                                                           train_sizes=np.linspace(0.1, 1.0, 5))\n",
        "    fig, ax = plt.subplots(figsize=(7,5))\n",
        "    ax.plot(train_sizes, train_scores.mean(1), \"o-\", label=\"Train\")\n",
        "    ax.plot(train_sizes, val_scores.mean(1), \"o-\", label=\"CV\")\n",
        "    ax.set_title(f\"{name} Learning Curve\")\n",
        "    ax.set_xlabel(\"Training examples\")\n",
        "    ax.set_ylabel(\"Accuracy\")\n",
        "    ax.legend()\n",
        "    savefig(fig, f\"{name}_learning_curve\"); plt.close(fig)\n",
        "\n",
        "def plot_xgb_learning_curve(model, X, y, name):\n",
        "    \"\"\"Custom incremental learning curve for XGBoost\"\"\"\n",
        "    train_sizes = np.linspace(0.1, 1.0, 6)\n",
        "    train_scores, val_scores = [], []\n",
        "    for frac in train_sizes:\n",
        "        n = int(len(X) * frac)\n",
        "        X_sub, y_sub = X[:n], y[:n]\n",
        "        m = xgb.XGBClassifier(**model.get_params())\n",
        "        m.fit(X_sub, y_sub, eval_set=[(X_val, y_val)], verbose=False)\n",
        "        train_preds = m.predict(X_sub)\n",
        "        val_preds = m.predict(X_val)\n",
        "        train_scores.append(accuracy_score(y_sub, train_preds))\n",
        "        val_scores.append(accuracy_score(y_val, val_preds))\n",
        "    fig, ax = plt.subplots(figsize=(7,5))\n",
        "    ax.plot(train_sizes*len(X), train_scores, \"o-\", label=\"Train\")\n",
        "    ax.plot(train_sizes*len(X), val_scores, \"o-\", label=\"Validation\")\n",
        "    ax.set_title(f\"{name} Learning Curve (Custom)\")\n",
        "    ax.set_xlabel(\"Training examples\")\n",
        "    ax.set_ylabel(\"Accuracy\")\n",
        "    ax.legend()\n",
        "    savefig(fig, f\"{name}_learning_curve\"); plt.close(fig)\n",
        "\n",
        "# Run both\n",
        "plot_learning_curve_custom(rf, X_train_s, y_train, \"RandomForest\", scaled=False)\n",
        "plot_xgb_learning_curve(xgb_baseline, X_train, y_train, \"XGBoost\")\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 8. Feature Importance (Permutation + XGB Gain)\n",
        "# -------------------------\n",
        "perm = permutation_importance(rf, X_test_s, y_test, n_repeats=20, random_state=SEED, n_jobs=-1)\n",
        "sorted_idx = perm.importances_mean.argsort()[-15:]\n",
        "fig, ax = plt.subplots(figsize=(7,5))\n",
        "ax.barh(np.array(feature_names)[sorted_idx], perm.importances_mean[sorted_idx])\n",
        "ax.set_title(\"RandomForest Feature Importance (Permutation)\")\n",
        "savefig(fig, \"rf_feature_importance\"); plt.close(fig)\n",
        "\n",
        "xgb_imp = pd.DataFrame({\"feature\": feature_names, \"importance\": xgb_baseline.feature_importances_})\n",
        "xgb_imp = xgb_imp.sort_values(\"importance\", ascending=False).head(15)\n",
        "fig, ax = plt.subplots(figsize=(7,5))\n",
        "sns.barplot(x=\"importance\", y=\"feature\", data=xgb_imp, palette=\"viridis\", ax=ax)\n",
        "ax.set_title(\"XGBoost Feature Importance (Gain)\")\n",
        "savefig(fig, \"xgb_feature_importance\"); plt.close(fig)\n",
        "\n",
        "# -------------------------\n",
        "# 9. SHAP Analysis\n",
        "# -------------------------\n",
        "SHAP_SAMPLE = 500\n",
        "X_shap = X_test.sample(min(SHAP_SAMPLE, X_test.shape[0]), random_state=SEED)\n",
        "explainer = shap.Explainer(xgb_baseline, X_train.sample(min(2000, X_train.shape[0]), random_state=SEED))\n",
        "shap_vals = explainer(X_shap)\n",
        "shap.summary_plot(shap_vals, X_shap, plot_type=\"bar\", show=False)\n",
        "plt.gcf().set_size_inches(7,5); plt.tight_layout()\n",
        "plt.savefig(SAVE_DIR/\"shap_summary.png\", dpi=FIG_DPI, bbox_inches=\"tight\"); plt.close()\n",
        "\n",
        "# -------------------------\n",
        "# 10. Save Models\n",
        "# -------------------------\n",
        "joblib.dump(rf, SAVE_DIR/\"rf.joblib\")\n",
        "joblib.dump(xgb_baseline, SAVE_DIR/\"xgb.joblib\")\n",
        "print(\"Models saved to:\", SAVE_DIR)\n",
        "\n",
        "# Bundle results\n",
        "shutil.make_archive(\"results_colab\", \"zip\", SAVE_DIR)\n",
        "files.download(\"results_colab.zip\")\n",
        "print(\"âœ… All done â€” artifacts downloaded.\")\n"
      ],
      "metadata": {
        "id": "XclwjaZ-c7hB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}